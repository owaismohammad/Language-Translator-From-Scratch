{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a31c7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "english = Path('train/english.txt')\n",
    "kannada = Path('train/kannada.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "21506e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "11713cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN,' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
    "                      'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', \n",
    "                      'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', \n",
    "                      'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', \n",
    "                      'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', \n",
    "                      'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', \n",
    "                      'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', \n",
    "                      'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', \n",
    "                      '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', \n",
    "                      '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = [\n",
    "    START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    ':', '<', '=', '>', '?', '@',\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
    "    'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "    'Y', 'Z',\n",
    "    '[', ']', '^', '_', '`', '//', '\\\\',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "    'y', 'z',\n",
    "    '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "960ac711",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "911ef965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98,\n",
       " {'<START>': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  '\"': 3,\n",
       "  '#': 4,\n",
       "  '$': 5,\n",
       "  '%': 6,\n",
       "  '&': 7,\n",
       "  \"'\": 8,\n",
       "  '(': 9,\n",
       "  ')': 10,\n",
       "  '*': 11,\n",
       "  '+': 12,\n",
       "  ',': 13,\n",
       "  '-': 14,\n",
       "  '.': 15,\n",
       "  '/': 16,\n",
       "  '0': 17,\n",
       "  '1': 18,\n",
       "  '2': 19,\n",
       "  '3': 20,\n",
       "  '4': 21,\n",
       "  '5': 22,\n",
       "  '6': 23,\n",
       "  '7': 24,\n",
       "  '8': 25,\n",
       "  '9': 26,\n",
       "  ':': 27,\n",
       "  '<': 28,\n",
       "  '=': 29,\n",
       "  '>': 30,\n",
       "  '?': 31,\n",
       "  '@': 32,\n",
       "  'A': 33,\n",
       "  'B': 34,\n",
       "  'C': 35,\n",
       "  'D': 36,\n",
       "  'E': 37,\n",
       "  'F': 38,\n",
       "  'G': 39,\n",
       "  'H': 40,\n",
       "  'I': 41,\n",
       "  'J': 42,\n",
       "  'K': 43,\n",
       "  'L': 44,\n",
       "  'M': 45,\n",
       "  'N': 46,\n",
       "  'O': 47,\n",
       "  'P': 48,\n",
       "  'Q': 49,\n",
       "  'R': 50,\n",
       "  'S': 51,\n",
       "  'T': 52,\n",
       "  'U': 53,\n",
       "  'V': 54,\n",
       "  'W': 55,\n",
       "  'X': 56,\n",
       "  'Y': 57,\n",
       "  'Z': 58,\n",
       "  '[': 59,\n",
       "  ']': 60,\n",
       "  '^': 61,\n",
       "  '_': 62,\n",
       "  '`': 63,\n",
       "  '//': 64,\n",
       "  '\\\\': 65,\n",
       "  'a': 66,\n",
       "  'b': 67,\n",
       "  'c': 68,\n",
       "  'd': 69,\n",
       "  'e': 70,\n",
       "  'f': 71,\n",
       "  'g': 72,\n",
       "  'h': 73,\n",
       "  'i': 74,\n",
       "  'j': 75,\n",
       "  'k': 76,\n",
       "  'l': 77,\n",
       "  'm': 78,\n",
       "  'n': 79,\n",
       "  'o': 80,\n",
       "  'p': 81,\n",
       "  'q': 82,\n",
       "  'r': 83,\n",
       "  's': 84,\n",
       "  't': 85,\n",
       "  'u': 86,\n",
       "  'v': 87,\n",
       "  'w': 88,\n",
       "  'x': 89,\n",
       "  'y': 90,\n",
       "  'z': 91,\n",
       "  '{': 92,\n",
       "  '|': 93,\n",
       "  '}': 94,\n",
       "  '~': 95,\n",
       "  '<PAD>': 96,\n",
       "  '<END>': 97})"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_to_index), english_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a41e6cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[243]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menglish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      2\u001b[39m     english_sentences = file.readlines()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(kannada, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/globalenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:320\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(io_open)\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_modified_open\u001b[39m(file, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m}\u001b[49m:\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m         )\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, *args, **kwargs)\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "with open(english, \"r\") as file:\n",
    "    english_sentences = file.readlines()\n",
    "    \n",
    "with open(kannada, \"r\") as file:\n",
    "    kannada_sentences = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d741d1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ebbe6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SENTENCES = 100000\n",
    "english_sentences= english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences= kannada_sentences[:TOTAL_SENTENCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "da1f13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = [x.rstrip('\\n') for x in english_sentences]\n",
    "kannada_sentences = [x.rstrip('\\n') for x in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9b03a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hes a scientist.',\n",
       "  \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
       "  '8 lakh crore have been looted.',\n",
       "  'I read a lot into this as well.',\n",
       "  \"She was found dead with the phone's battery exploded close to her head the following morning.\"],\n",
       " ['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       "  '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       "  'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.',\n",
       "  'ಇದರ ಬಗ್ಗೆ ನಾನೂ ಸಾಕಷ್ಟು ಓದಿದ್ದೇನೆ.',\n",
       "  'ಆಕೆಯ ತಲೆಯ ಹತ್ತಿರ ಇರಿಸಿಕೊಂಡಿದ್ದ ಫೋನ್\\u200cನ ಬ್ಯಾಟರಿ ಸ್ಫೋಟಗೊಂಡು ಆಕೆ ಮೃತಪಟ್ಟಿದ್ದಾಳೆ ಎನ್ನಲಾಗಿದೆ.'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:5], kannada_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5e09d09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 639)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(x) for x in english_sentences), max(len(x) for x in kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3d211ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kannada_sentences), len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "42f07848",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_length(sentence, max_seq_length):\n",
    "    if len(sentence) <  (max_seq_length-1):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "        \n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for char in sentence:\n",
    "        if char not in vocab:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "valid_sentence_index = []\n",
    "for index in range(TOTAL_SENTENCES):\n",
    "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_index.append(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "56795251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 100000\n",
      "Number of valid sentences: 81916\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "43a1cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kannada = [kannada_sentences[i] for i in valid_sentence_index]\n",
    "english = [english_sentences[i] for i in valid_sentence_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e65e6a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       "  '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       "  'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.'],\n",
       " ['Hes a scientist.',\n",
       "  \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
       "  '8 lakh crore have been looted.'])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada[:3], english[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a738a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, english, kannada):\n",
    "        self.english = english\n",
    "        self.kannada = kannada\n",
    "    def __len__(self):\n",
    "        return len(self.english)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english[idx], self.kannada[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5d100212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(english=english, kannada=kannada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "da781c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "82425b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, language_to_index, start_token = True, end_token= True):\n",
    "    sentence_word_indices = [language_to_index[token] for token in sentence]\n",
    "    \n",
    "    if start_token:\n",
    "        sentence_word_indices.insert(0,language_to_index[START_TOKEN])\n",
    "    if end_token:\n",
    "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
    "        \n",
    "    for _ in range(len(sentence), max_sequence_length):\n",
    "        sentence_word_indices.append(language_to_index[PADDING_TOKEN])\n",
    "    return torch.tensor(sentence_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e7a9edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token( dataset:torch.utils.data.Dataset):\n",
    "    eng_tokenized, kn_tokenized = [], []\n",
    "    for sentence_num in range(length):\n",
    "        eng_sentence, kn_sentence = dataset[sentence_num][0], dataset[sentence_num][1]\n",
    "        eng_tokenized.append(tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
    "        kn_tokenized.append( tokenize(kn_sentence, kannada_to_index, start_token=True, end_token=True) )\n",
    "    eng_tokenized = torch.stack(eng_tokenized)\n",
    "    kn_tokenized = torch.stack(kn_tokenized)\n",
    "    return eng_tokenized, kn_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "af17bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81916, 81916)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenized, kn_tokenized = generate_token(dataset)\n",
    "len(eng_tokenized), len(kn_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0e8699fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformer_heads/SentenceEmbedding.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transformer_heads/SentenceEmbedding.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from transformer_heads.PositionEncoding import PositionEncoding\n",
    "class SentenceEmbedding(nn.Module):\n",
    "    def __init__(self, max_sequence_length:int,\n",
    "                 d_model:int,\n",
    "                 language_to_idx:dict,\n",
    "                 START_TOKEN:str,\n",
    "                 END_TOKEN:str,\n",
    "                 PADDING_TOKEN:str):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(language_to_idx)\n",
    "        self.max_seq = max_sequence_length\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.language_to_idx = language_to_idx\n",
    "        self.Position_Encoder = PositionEncoding(self.max_seq, d_model)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "        \n",
    "        \n",
    "    def batch_tokenize(self, batch, start_token = True, end_token = True):\n",
    "        \n",
    "        def tokenize(sentence, start_token=True, end_token=True):\n",
    "            sentence_word_indices = [self.language_to_idx[token] for token in sentence]\n",
    "                        \n",
    "            if start_token==True:\n",
    "                sentence_word_indices.insert(0, self.language_to_idx[self.START_TOKEN])\n",
    "            if end_token:\n",
    "                sentence_word_indices.append(self.language_to_idx[self.END_TOKEN])\n",
    "            for _ in range(len(sentence_word_indices),self.max_seq) :\n",
    "                sentence_word_indices.append(self.language_to_idx[self.PADDING_TOKEN])\n",
    "                \n",
    "            if len(sentence_word_indices) > self.max_seq:\n",
    "                sentence_word_indices = sentence_word_indices[:self.maxseq]\n",
    "            return sentence_word_indices\n",
    "        \n",
    "        \n",
    "        tokenized = []\n",
    "        for sentence_num in range(len(batch)):\n",
    "            tokenized.append( tokenize(batch[sentence_num], start_token= start_token, end_token=end_token))\n",
    "        \n",
    "        tokenized = torch.tensor(tokenized)  \n",
    "        return tokenized\n",
    "    \n",
    "    \n",
    "    def forward(self,x, start_token= True, end_token = True):\n",
    "        x = self.batch_tokenize(x, start_token, end_token)\n",
    "        x= self.embedding(x)\n",
    "        pos = self.Position_Encoder(x)\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e42f182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['Hes a scientist.',\n",
    "    \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
    "    '8 lakh crore have been looted.']\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gen_embed = SentenceEmbedding(max_sequence_length=200,\n",
    "                              d_model = 512,\n",
    "                              language_to_idx=english_to_index,\n",
    "                              START_TOKEN=START_TOKEN,\n",
    "                              END_TOKEN=END_TOKEN,\n",
    "                              PADDING_TOKEN=PADDING_TOKEN,\n",
    "                              )\n",
    "\n",
    "y = gen_embed(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfec61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268ba42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
