{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccfc611",
   "metadata": {},
   "source": [
    "## input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d51adbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4538, 0.7531, 0.3474, 0.6928],\n",
       "        [0.4008, 0.5153, 0.2191, 0.4421],\n",
       "        [0.7622, 1.2977, 0.4161, 0.8186],\n",
       "        [0.6235, 0.9334, 0.4064, 0.7614]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "L, dk, dv = 4,8,8\n",
    "\n",
    "q = torch.rand(L, dk)\n",
    "k = torch.rand(L, dk)\n",
    "v = torch.rand(L, dv)\n",
    "\n",
    "attention = (q @ k.T )/ math.sqrt(dk)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b91f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0776), tensor(0.0812), tensor(0.0734))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(),k.var(), attention.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9291e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = torch.tril(torch.ones(4,4))\n",
    "tri[tri == 0] = -torch.inf\n",
    "tri[tri == 1] = 0\n",
    "scaled = attention + tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f3de74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4714, 0.5286, 0.0000, 0.0000],\n",
       "        [0.2928, 0.5001, 0.2071, 0.0000],\n",
       "        [0.2317, 0.3159, 0.1865, 0.2660]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(scaled, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b79237d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc01f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.rand(4,8)\n",
    "k.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7b5dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(k, q, v, mask=None):\n",
    "    \n",
    "    attention = (k @q.T) / math.sqrt(k.shape[-1])\n",
    "    if mask is not None:\n",
    "        attention = attention + mask\n",
    "    \n",
    "    scaled_attention = softmax(attention)\n",
    "    out = scaled_attention @ v\n",
    "    return out, attention,scaled_attention\n",
    "\n",
    "def softmax(attention):\n",
    "    return torch.softmax(attention,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89d89210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2735, 0.9688, 0.0151, 0.2840, 0.5233, 0.7624, 0.9583, 0.4519],\n",
       "         [0.1744, 0.7238, 0.1919, 0.3430, 0.4853, 0.5910, 0.7559, 0.6465],\n",
       "         [0.5019, 0.8354, 0.5186, 0.6100, 0.4572, 0.4551, 0.8194, 0.5343],\n",
       "         [0.3700, 0.7754, 0.5910, 0.4546, 0.3627, 0.4088, 0.7136, 0.5396]]),\n",
       " tensor([[0.4418,   -inf,   -inf,   -inf],\n",
       "         [0.6809, 0.4334,   -inf,   -inf],\n",
       "         [0.8124, 0.4710, 0.9954,   -inf],\n",
       "         [0.3359, 0.3480, 0.5736, 0.5095]]),\n",
       " tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5615, 0.4385, 0.0000, 0.0000],\n",
       "         [0.3435, 0.2441, 0.4124, 0.0000],\n",
       "         [0.2237, 0.2264, 0.2837, 0.2661]]),\n",
       " tensor([[0.2735, 0.9688, 0.0151, 0.2840, 0.5233, 0.7624, 0.9583, 0.4519],\n",
       "         [0.0474, 0.4100, 0.4184, 0.4186, 0.4365, 0.3715, 0.4966, 0.8958],\n",
       "         [0.9611, 0.9760, 0.9973, 0.9948, 0.4144, 0.2487, 0.8947, 0.3891],\n",
       "         [0.0953, 0.7097, 0.7888, 0.0529, 0.1096, 0.3139, 0.4995, 0.4708]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, att,sc = self_attention(k,q,v,mask=tri)\n",
    "\n",
    "out, att, sc, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8159e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seq_len = 4\n",
    "batch_size =1 \n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "\n",
    "x = torch.rand((batch_size, seq_len , input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f940e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5269, 0.1897, 0.8433,  ..., 0.6816, 0.6451, 0.4034],\n",
       "         [0.0545, 0.9215, 0.4575,  ..., 0.4892, 0.6535, 0.8174],\n",
       "         [0.7029, 0.7112, 0.7370,  ..., 0.4391, 0.2639, 0.1980],\n",
       "         [0.7231, 0.9426, 0.8046,  ..., 0.4923, 0.3170, 0.9782]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08bbe6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_layer = nn.Linear(input_dim,d_model*3)\n",
    "qkv = qkv_layer(x)\n",
    "\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98b849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "\n",
    "qkv = qkv.reshape(batch_size,seq_len,num_heads,head_dim*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51f00151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fcc28cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0,2,1,3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f79026f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q,k,v = qkv.chunk(3,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "33053dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape,v.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1398943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 64, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.transpose(-1,-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1460f724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.matmul(q, k.transpose(-1,-2))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a787943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = k.shape[-1]\n",
    "scaled = torch.softmax(torch.matmul(q, k.transpose(-1,-2))/math.sqrt(dk), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a16edda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f2c48fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.shape,float('-inf'))\n",
    "mask[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2bc20483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d79f2f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2589,   -inf,   -inf,   -inf],\n",
       "         [0.2492, 0.2463,   -inf,   -inf],\n",
       "         [0.2507, 0.2354, 0.2499,   -inf],\n",
       "         [0.2544, 0.2305, 0.2565, 0.2586]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask += scaled\n",
    "mask[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8b7ac0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof = torch.softmax(mask,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c6a0e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5007, 0.4993, 0.0000, 0.0000],\n",
       "        [0.3351, 0.3300, 0.3349, 0.0000],\n",
       "        [0.2511, 0.2452, 0.2516, 0.2521]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sof[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5c8fd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot(q,k,v,mask=None):\n",
    "    dk = k.shape[-1]\n",
    "    attention = torch.matmul(q,k.transpose(-1,-2))/ math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        attention = attention +mask\n",
    "    scaled = torch.softmax(attention, dim=-1)\n",
    "    val = scaled @ v\n",
    "    return scaled, val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1392ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = scaled_dot(q,k,v)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e85bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "max_seq_len = 10\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b27b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_i = torch.arange(0, d_model,2).float()\n",
    "denom_even = torch.pow(10000, even_i/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b55c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_i = torch.arange(1,d_model, 2).float()\n",
    "denom_odd = torch.pow(10000, (odd_i-1)/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77f1153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.0000,  21.5443, 464.1590]),\n",
       " tensor([  1.0000,  21.5443, 464.1590]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom_odd, denom_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de48ee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(0, max_seq_len).reshape(max_seq_len,1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b1d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_pe = torch.sin(position/denom_even)\n",
    "odd_pe = torch.cos(position / denom_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e603f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8415,  0.0464,  0.0022],\n",
       "         [ 0.9093,  0.0927,  0.0043],\n",
       "         [ 0.1411,  0.1388,  0.0065],\n",
       "         [-0.7568,  0.1846,  0.0086],\n",
       "         [-0.9589,  0.2300,  0.0108],\n",
       "         [-0.2794,  0.2749,  0.0129],\n",
       "         [ 0.6570,  0.3192,  0.0151],\n",
       "         [ 0.9894,  0.3629,  0.0172],\n",
       "         [ 0.4121,  0.4057,  0.0194]]),\n",
       " tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "         [ 0.5403,  0.9989,  1.0000],\n",
       "         [-0.4161,  0.9957,  1.0000],\n",
       "         [-0.9900,  0.9903,  1.0000],\n",
       "         [-0.6536,  0.9828,  1.0000],\n",
       "         [ 0.2837,  0.9732,  0.9999],\n",
       "         [ 0.9602,  0.9615,  0.9999],\n",
       "         [ 0.7539,  0.9477,  0.9999],\n",
       "         [-0.1455,  0.9318,  0.9999],\n",
       "         [-0.9111,  0.9140,  0.9998]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_pe,odd_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e100820",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.zeros((10,6))\n",
    "x[:,0::2]= even_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45549b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,1::2]=odd_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecd48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "369c7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,max_seq_len:int, d_model:int):\n",
    "        super().__init__()\n",
    "        self.maxseq = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self):\n",
    "        pos = torch.arange(0, self.maxseq).reshape(self.maxseq,1)\n",
    "        i = torch.arange(0, d_model, 2)\n",
    "        denom = torch.pow(10000, i/self.d_model)\n",
    "        odd_pos = torch.cos(pos/denom)\n",
    "        even_pos = torch.sin(pos/denom)\n",
    "        x_das = torch.zeros(self.maxseq,self.d_model)\n",
    "        x_das[:,0::2] = even_pos\n",
    "        x_das[:,1::2] = odd_pos\n",
    "        return x_das\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "202e2a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PositionalEncoding(10,6)\n",
    "a= model.forward()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4d8c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
